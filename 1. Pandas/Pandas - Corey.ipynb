{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/survey_results_public.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape attrivute tell us dimensions(rows, columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Info method will give us detailed aboout the schema of the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below method will set the max columns to 85 so we can see all the columns of the dataset\n",
    "pd.set_option('display.max_columns', 85)\n",
    "\n",
    "pd.set_option('display.max_rows', 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_df = pd.read_csv('data/survey_results_schema.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_df"
   ]
  },
  {
   "source": [
    "## 2. DataFrame and Series"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### DataRaframe :  \n",
    "DataRaframe is basically a two dimensional table. Usally referred to as **`df`** in many Data Scince projects.\n",
    "DataRaframe can have rows and columns similiar to worksheet. And this is mainly helpful to analyze tabular data. And DataRaframe also acts like a contians of Series.\n",
    "### Series :  \n",
    "Series is like a array of data.\n",
    "\n",
    "### `Note: DataRaframe and Series  may sound like aregular data types but they come with a huge set of attributes from pandas libraris to deal with real life Data Scince problems.`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To access a single column in a DataFrame. Please observe that every columns inside a datafrma has a series type.\n",
    "print(df['Country']) #Method 1 - Always preferred.\n",
    "print(df.Country)  #Method 2\n",
    "print(\"====================================\")\n",
    "print(\"Data Type of a column in DataFrame: \" + str(type(df['Country'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To access Muliple columns we can use [] and pass a list of clumns which will agian go inside []\n",
    "df[['Country','CurrencyDesc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see all the list of columns we can do as.\n",
    "# Here you will observe that it returns Index because pandas DataFrame store two type of indexes for rows (index = 0) and columns (index = 1) will discuss later in details.\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For accessing rows we can use loc or iloc idexes\n",
    "# iloc allows us to access thw rows by integer location\n",
    "df.iloc[1]\n",
    "#it gives us details of the row on 1st indesx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use multiple rows using slicing technique for multi dimensional array\n",
    "df.iloc[[0,1],[0,2]]\n",
    "#df.iloc[[rows],[columns]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use multiple rows using a list or\n",
    "df.iloc[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_head3 = df.head(3)\n",
    "df_head3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While iloc uses integer index, loc uses label for the rows. In our case we have our index columns set by defaults so the 0,1,2... these are actually labels asscoiated with the rows. So to access a row using the label we can us loc. e.ge if we have defined a Name column as an index column then the name will become the label for a particular row.\n",
    "df_head3.loc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[0,2],['Hobbyist','OpenSourcer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get unique list of values in a column we can use .unique() function\n",
    "df['OpenSourcer'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get count of each unique value inside the columns\n",
    "df['OpenSourcer'].value_counts()"
   ]
  },
  {
   "source": [
    "## 3. Indexes  - Set, Reset and Filtering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Indexing in Pandas :**\n",
    "Indexing in pandas means simply selecting particular rows and columns of data from a DataFrame. Indexing could mean selecting all the rows and some of the columns, some of the rows and all of the columns, or some of each of the rows and columns. `Indexing can also be known as Subset Selection.`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Dataframe.[]** : This function also known as indexing operator\n",
    "\n",
    "**Dataframe.loc[]** : This function is used for labels.\n",
    "\n",
    "**Dataframe.iloc[]** : This function is used for positions or integer based\n",
    "\n",
    "**Dataframe.ix[]** : This function is used for both label and integer based\n",
    "\n",
    "Collectively, they are called the indexers. These are by far the most common ways to index data. These are four function which help in getting the elements, rows, and columns from a DataFrame.\n",
    " \n",
    "**`Indexing a Dataframe using indexing operator [] :`**\n",
    "Indexing operator is used to refer to the square brackets following an object. The .loc and .iloc indexers also use the indexing operator to make selections. In this indexing operator to refer to df[]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use se_index function to explicitly define our index it can be a existing column from the DataFrame or or set of columns or we can use a python list to define index.\n",
    "df.set_index('Respondent', inplace=True)\n",
    "\n",
    "#Setting Respondent as index will make it bold and remove an existing index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can check the index as an attribute of the dataframe\n",
    "df.index\n",
    "# Now its will become the label of the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you mistakenly set a wrong index then you can simply reset it as below\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can aslo specify a index column while importing the data from data source\n",
    "df = pd.read_csv('data/survey_results_public.csv', index_col='Respondent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets creat Column as index so we can loc it and find what the column name means\n",
    "schema_df = pd.read_csv('data/survey_results_schema.csv',index_col='Column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can sort the dataset using a column as below\n",
    "schema_df.sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check at what Age1stCode means in the dataset\n",
    "schema_df.loc['Age1stCode']"
   ]
  },
  {
   "source": [
    "<a id='hashtag_suffix'></a>\n",
    "## 4. Filtering - using Conditionals to filter Rows and Columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Filtering is basically the mainn thing to learn in pandas because its the main thing for what we use pandas when we start a project.\n",
    "We filter the data that we want fr ananlysis from the data that we dont."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know that we can select a columns using []. We can simply check for a value against the selected column\n",
    "df['Hobbyist'] == 'Yes' # This basically returns a mask containing true for all the maches\n",
    "#We can simply assign it to a variable and use this to further filter the data. though its not neccesary but a wasy to do so.schema_df\n",
    "filt = df['Hobbyist'] == 'Yes'\n",
    "#Now that we have the mask inside a variable we can use this to filtr our dataset \n",
    "df[filt]\n",
    "#Now you can see that we only got the Hobbyist list below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to filter is use .loc indexer and\n",
    "df.loc[filt].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The benefit of using .loc is that we can still grab a specific column\n",
    "df.loc[filt, 'Country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can aslo use logical operators like &(and) and |(or) or ~(not) inside for muliple conditios [~ will negate the filter]\n",
    "# To search a hobbysit and aslo a open sources\n",
    "filt = (df['Hobbyist'] == 'Yes') & ~(df['OpenSourcer'] == 'Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check what open source did they work on\n",
    "df.loc[filt,['Hobbyist','OpenSourcer','OpenSource']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Country'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What if you want to check for multiple values against countries and select th results\n",
    "countries = ['United Kingdom', 'United States', 'Ukraine', 'Canada', 'India', 'New Zealand','Germany', 'Australia']\n",
    "filt2 = df['Country'].isin(countries)\n",
    "df.loc[filt2,'Country'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets say if we cant to check if the user knows python as a language\n",
    "df.columns # check columns name found to be 'LanguageWorkedWith'\n",
    "df['LanguageWorkedWith']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #But it has multiple values we need to check if these values contains python or not\n",
    " filt3 = df['LanguageWorkedWith'].str.contains('Python',na=False) #Setting Na to false to avoid the blank vlaues in filtering\n",
    " df.loc[filt3, 'LanguageWorkedWith']\n",
    " # So the below list will conatin only rows that has Python in it. "
   ]
  },
  {
   "source": [
    "## 5. Updating Rows and Columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometime during data manipulation we need to chnage column label and sometimes re-evaluate the values in our dataset\n",
    "# Lets first update our columns and then see how to go for rows\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select only few columns\n",
    "df5 = df[df.columns[0:2]].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To upper case all column names. We will use a list comprehension to do this\n",
    "df5.columns = [x.upper() for x in df5.columns]\n",
    "df5 # All "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want to rename our columns then we can use the rename function which would take a dictionary argument\n",
    "df5.rename(columns={'RESPONDENT':'UserID','MAINBRANCH':'User Status','HOBBYIST':'Is Hobbyist'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove spaces and replace with underscore\n",
    "df5.columns = df5.columns.str.replace(' ','_')\n",
    "df5"
   ]
  },
  {
   "source": [
    "### ` - > Updating a row.`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To update a row you first need to select the row that you can either do using a loc i.e. the label method or using a condition.abs\n",
    "df5.loc[4] = [5,'I am Power BI Developer','No']\n",
    "df5.loc[4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or if we want to update a speciific column entry for a specific row we can select using loc and select the column name too to update it.\n",
    "df5.loc[4,'Is_Hobbyist'] = ['Yes']\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is another function specifically made for selecting and updating a single value i.e. at we can use as\n",
    "df5.at[4,'Is_Hobbyist'] = 'No'\n",
    "df5.head()"
   ]
  },
  {
   "source": [
    "### `-> Filter a row to update the data`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update a single row by filtering\n",
    "filt5 = (df5['UserID'] == 4)\n",
    "df5.loc[filt5, 'User_Status'] = 'I am a Data Scientist'\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how do I update multiple row or full columns\n",
    "df5['Is_Hobbyist'] = df5['Is_Hobbyist'].str.lower()\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use apply to apply a function on the column\n",
    "df5['Is_Hobbyist'].apply(len) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply can be used to get info about data but also to chnage it\n",
    "def Update_Is_Hobbyist (Is_Hobbyist):\n",
    "    return Is_Hobbyist.upper()\n",
    "df5['Is_Hobbyist'] = df5['Is_Hobbyist'].apply(Update_Is_Hobbyist)\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also use lambda funtion inside apply instead of writing a complete function\n",
    "\n",
    "df5['Is_Hobbyist'] = df5['Is_Hobbyist'].apply(lambda x: x.lower())\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to apply to the complete dat frame you should use applymap()\n",
    "df5.applymap(str).applymap(len) # Since the USer_ID is a int and you cant do len funtion on an int value so converting to str and then applying len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use .map function to change values using a dictionay but map will substitue NaN if does no tfind the dictinary match\n",
    "df5['Is_Hobbyist'].map({'yes':'Yes','no':'No'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IF we use replace instead it will keep oroginal values rather\n",
    "df5['Is_Hobbyist'] = df5['Is_Hobbyist'].replace({'Yes':True,'No':False})\n",
    "df5"
   ]
  },
  {
   "source": [
    "**`Links for refrence : `**\n",
    "\n",
    "https://www.geeksforgeeks.org/indexing-and-selecting-data-with-pandas/\n",
    "\n",
    "https://nbsphinx.readthedocs.io/en/0.2.3/markdown-cells.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}